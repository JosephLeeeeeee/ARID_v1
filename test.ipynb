{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import socket\n",
    "import logging\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.nn.parallel\n",
    "import torch.distributed as dist\n",
    "\n",
    "import dataset\n",
    "from train_model import train_model\n",
    "from network.symbol_builder import get_symbol\n",
    "\n",
    "torch.backends.cudnn.enabled = False\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"PyTorch Video Classification Parser\")\n",
    "# debug\n",
    "parser.add_argument('--debug-mode', type=bool, default=True,\n",
    "                    help=\"print all setting for debugging.\")\n",
    "# io\n",
    "parser.add_argument('--dataset', default='ARID',\n",
    "                    help=\"path to dataset\")\n",
    "parser.add_argument('--clip-length', type=int, default=16,\n",
    "                    help=\"define the length of each input sample.\")\n",
    "parser.add_argument('--train-frame-interval', type=int, default=2,\n",
    "                    help=\"define the sampling interval between frames.\")\n",
    "parser.add_argument('--val-frame-interval', type=int, default=2,\n",
    "                    help=\"define the sampling interval between frames.\")\n",
    "parser.add_argument('--task-name', type=str, default='',\n",
    "                    help=\"name of current task, leave it empty for using folder name\")\n",
    "parser.add_argument('--model-dir', type=str, default=\"./exps/models/archive\",\n",
    "                    help=\"set logging file.\")\n",
    "parser.add_argument('--log-file', type=str, default=\"\",\n",
    "                    help=\"set logging file.\")\n",
    "# device\n",
    "parser.add_argument('--gpus', type=str, default=\"0,1,2,3,4,5,6,7\",\n",
    "                    help=\"define gpu id\")\n",
    "# algorithm\n",
    "parser.add_argument('--network', type=str, default='RESNET',\n",
    "                    help=\"chose the base network\")\n",
    "# initialization with priority (the next step will overwrite the previous step)\n",
    "# - step 1: random initialize\n",
    "# - step 2: load the 2D pretrained model if `pretrained_2d' is True\n",
    "# - step 3: load the 3D pretrained model if `pretrained_3d' is defined\n",
    "# - step 4: resume if `resume_epoch' >= 0\n",
    "parser.add_argument('--pretrained_2d', type=bool, default=True,\n",
    "                    help=\"load default 2D pretrained model.\")\n",
    "parser.add_argument('--pretrained_3d', type=str,\n",
    "                    default=None,\n",
    "                    help=\"load default 3D pretrained model.\")\n",
    "parser.add_argument('--resume-epoch', type=int, default=-1,\n",
    "                    help=\"resume train\")\n",
    "# optimization\n",
    "parser.add_argument('--fine-tune', type=bool, default=True,\n",
    "                    help=\"apply different learning rate for different layers\")\n",
    "parser.add_argument('--batch-size', type=int, default=2,\n",
    "                    help=\"batch size\")\n",
    "parser.add_argument('--lr-base', type=float, default=0.01,\n",
    "                    help=\"learning rate\")\n",
    "parser.add_argument('--lr-steps', type=list, default=[int(1e4*x) for x in [2, 4, 8]],\n",
    "            help=\"number of samples to pass before changing learning rate\")\n",
    "parser.add_argument('--lr-factor', type=float, default=0.1,\n",
    "                    help=\"reduce the learning with factor\")\n",
    "parser.add_argument('--save-frequency', type=float, default=1,\n",
    "                    help=\"save once after N epochs\")\n",
    "parser.add_argument('--end-epoch', type=int, default=50,\n",
    "                    help=\"maxmium number of training epoch\")\n",
    "parser.add_argument('--random-seed', type=int, default=1,\n",
    "                    help='random seed (default: 1)')\n",
    "# distributed training\n",
    "parser.add_argument('--backend', default='nccl', type=str, choices=['gloo', 'nccl'],\n",
    "                    help='Name of the backend to use')\n",
    "parser.add_argument('--world-size', default=1, type=int,\n",
    "                    help='number of distributed processes')\n",
    "parser.add_argument('--dist-url', default='tcp://192.168.0.11:23456', type=str,\n",
    "                    help='url used to set up distributed training')\n",
    "# dark dataset config\n",
    "parser.add_argument('--is-dark', action='store_true')\n",
    "parser.add_argument('--use-flow', action='store_true')\n",
    "parser.add_argument('--use-segments', action='store_true')\n",
    "parser.add_argument('--segments', default=3, type=int)\n",
    "\n",
    "def autofill(args):\n",
    "    # customized\n",
    "    if not args.task_name:\n",
    "        args.task_name = os.path.basename(os.getcwd())\n",
    "    if not args.log_file:\n",
    "        if os.path.exists(\"./exps/logs\"):\n",
    "            args.log_file = \"./exps/logs/{}_at-{}.log\".format(args.task_name, socket.gethostname())\n",
    "        else:\n",
    "            args.log_file = \".{}_at-{}.log\".format(args.task_name, socket.gethostname())\n",
    "    # fixed\n",
    "    args.model_prefix = os.path.join(args.model_dir, args.task_name)\n",
    "    return args\n",
    "\n",
    "def set_logger(log_file='', debug_mode=False):\n",
    "    if log_file:\n",
    "        if not os.path.exists(\"./\"+os.path.dirname(log_file)):\n",
    "            os.makedirs(\"./\"+os.path.dirname(log_file))\n",
    "        handlers = [logging.FileHandler(log_file), logging.StreamHandler()]\n",
    "    else:\n",
    "        handlers = [logging.StreamHandler()]\n",
    "\n",
    "    \"\"\" add '%(filename)s:%(lineno)d %(levelname)s:' to format show source file \"\"\"\n",
    "    logging.basicConfig(level=logging.DEBUG if debug_mode else logging.INFO,\n",
    "                format='%(asctime)s: %(message)s',\n",
    "                datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                handlers = handlers)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # set args\n",
    "    args = parser.parse_args()\n",
    "    args = autofill(args)\n",
    "\n",
    "    if not args.use_segments:\n",
    "        args.segments = 1\n",
    "\n",
    "    set_logger(log_file=args.log_file, debug_mode=args.debug_mode)\n",
    "    logging.info(\"Using pytorch {} ({})\".format(torch.__version__, torch.__path__))\n",
    "    logging.info(\"Start training with args:\\n\" +\n",
    "                 json.dumps(vars(args), indent=4, sort_keys=True))\n",
    "\n",
    "    # set device states\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpus # before using torch\n",
    "    assert torch.cuda.is_available(), \"CUDA is not available\"\n",
    "    torch.manual_seed(args.random_seed)\n",
    "    torch.cuda.manual_seed(args.random_seed)\n",
    "\n",
    "    # distributed training\n",
    "    args.distributed = args.world_size > 1\n",
    "    if args.distributed:\n",
    "        import re, socket\n",
    "        rank = int(re.search('192.168.0.(.*)', socket.gethostname()).group(1))\n",
    "        logging.info(\"Distributed Training (rank = {}), world_size = {}, backend = `{}'\".format(\n",
    "                     rank, args.world_size, args.backend))\n",
    "        dist.init_process_group(backend=args.backend, init_method=args.dist_url, rank=rank,\n",
    "                                group_name=args.task_name, world_size=args.world_size)\n",
    "\n",
    "    # load dataset related configuration\n",
    "    dataset_cfg = dataset.get_config(name=args.dataset)\n",
    "\n",
    "    # creat model with all parameters initialized\n",
    "    net, input_conf = get_symbol(name=args.network, is_dark=args.is_dark,\n",
    "                     pretrained=args.pretrained_2d if args.resume_epoch < 0 else None,\n",
    "                     print_net=True if args.distributed else False,\n",
    "                     **dataset_cfg)\n",
    "\n",
    "    # training\n",
    "    kwargs = {}\n",
    "    kwargs.update(dataset_cfg)\n",
    "    kwargs.update({'input_conf': input_conf})\n",
    "    kwargs.update(vars(args))\n",
    "    train_model(sym_net=net, **kwargs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
